Roles & Responsibilities

• Take ownership of a well-defined subcomponent of a production AI system — such as a preprocessing pipeline, model training module, evaluation framework, or embedded deployment logic.
• Develop and fine-tune machine learning models in key domains:
o Object detection (e.g., pest detection, satellite imagery analysis)
o LLM-based agronomic assistants and Retrieval-Augmented Generation (RAG) systems
o Multi-class classification tasks relevant to agriculture and sustainability
• Design experiments, evaluate model performance using rigorous metrics, and iterate with supervision but high autonomy.
• Implement clean, modular, and reproducible code aligned with Doktar’s production standards (version control, testing, CI/CD).
• Collaborate with ML Engineers, and Product Managers to ensure that model outputs deliver agronomic and business value.
• Document your work clearly, present progress in reviews, and contribute to internal knowledge-sharing platforms.
• Stay up to date with ML/AI research; bring relevant insights to the team and actively participate in our AI reading group.

Requirements

• 3rd or 4th-year BSc student or an active MSc student in Computer Science, Artificial Intelligence, Electrical Engineering, or a related technical field, preferably from a top-tier university with a strong technical foundation.
• Strong programming skills in Python and hands-on experience with at least one major ML framework (e.g., PyTorch, TensorFlow, scikit-learn).
• Solid grasp of ML fundamentals: supervised learning, overfitting/regularization, model evaluation metrics — along with foundational knowledge of statistics (e.g., distributions, hypothesis testing, variance).
• Demonstrated interest (through coursework, personal projects, or research) in at least one of the following:
o Computer Vision
o Natural Language Processing / LLMs
o Embedded / Edge AI
o Machine Learning or MLOps practices
• Bonus: Experience with cloud platforms (Azure or AWS), vector databases, or deploying models into production environments.

Generative AI Engineer Engineer


As a Generative AI Engineer ,you will take on a role in developing, implementing, and optimizing the company's artificial intelligence projects. You will utilize artificial intelligence technologies to develop new products and services, manage data analysis and model training processes, and determine the company's artificial intelligence strategy.


Responsibilities:


    Plan, design, and implement Generative AI projects.
    Integrate artificial intelligence technologies into existing products and services.
    Create datasets suitable for the model by conducting data analysis.
    Manage the model training, validation, and testing processes.
    Contribute to the company's strategy by staying up-to-date with technology trends.
    Collaborate within the team with strong written and verbal communication skills

 

Qualifications:


    Proficiency in programming languages.
    Mastery of artificial intelligence libraries such as TensorFlow, PyTorch, Theano, and Microsoft Cognitive Toolkit.
    Experience in large dataset analysis and preprocessing.
    Problem analysis and solving skills.
    Innovative thinking and a propensity for teamwork.
    Proficiency in English.

About you

    3+ years of consultant experience and solid background in (analytics) project management
    Excellent knowledge of Microsoft Office Excel and PowerPoint
    Good communication skills in English (C1 level)
    Master's degree in technical / data-driven / business field (engineering, computer science, econometrics or likewise)
    Proven project/Program management skills
    Excellent communication skills, both verbally and in writing, being able to align, engage and advise various stakeholders, including senior ones
    High adaptability: Content-wise can deal with the high degree of ambiguity that comes with the exploration request
    Can do/go-getter mentality – go out of your own responsibilities and comfort zone to achieve the team target


Nice to have:

Experience in a matrix set up is a strong plus.


How to Succeed

    Drive internal and external strategic and analytics projects including scoping, analysis, and development of recommendations, including advising and providing consultancy to the CAO on various related topics such as organizational design, analytics teams way of working, governance, data fluency, strategic partnership such as Kickstart AI, EU AI Act, Generative AI initiative coordination
    Actively support ING Analytics with stakeholder management towards existing and potential senior stakeholders to drive business development of analytics solutions; support tribes in related project scoping.
    Actively monitor ING Analytics’ portfolio deliveries and support quarterly review cycle.
    Support daily operations of the ING Analytics department including (but not limited to) finance, and resource planning; prioritize analytics agenda to align with organizational roadmap.
    Support daily operations of the ING Analytics department including (but not limited to) finance, and resource planning; prioritize analytics agenda to align with organizational roadmap.
    Support the creation and translation of the analytics strategy into objectives and roadmaps.
    Support the implementation of broader data-driven transformation at ING, incl. location strategy, country organization, financial planning, governance.


What Awaits You, What Will Be Your Responsibilities?


    Researching, designing, implementing, and evaluating machine learning approaches and models.
    Assisting in analyzing large datasets using statistical techniques and machine learning algorithms.
    Supporting the development, implementation, and evaluation of predictive models and data-driven solutions to address business challenges.
    Preprocessing and cleaning raw data to ensure its quality, integrity, and usability for analysis.
    Applying data wrangling techniques to handle missing values, outliers, and inconsistencies in the data.
    Creating visualizations, charts, and dashboards to communicate insights and findings from data analysis effectively.
    Collaborating with senior data scientists, analysts, and business stakeholders to understand project requirements and objectives.
    Contributing ideas and insights to team discussions and brainstorming sessions.
    Staying updated on the latest trends, tools, and techniques in data science and machine learning.
    Documenting analysis methods, findings, and results in clear and concise reports.
    Preparing presentations and documentation to communicate project outcomes to stakeholders and team members.
    Deploying machine learning models into production environments using containerization, orchestration, and model serving frameworks.
    Exploring, fine-tuning, and applying Large Language Models (LLMs) and agentic AI solutions to address business needs and automation opportunities.




What will be the qualifications we expect from you?


    BS Degree in Statistics, Computer Science/Engineering, Industrial Engineering (or other related engineering fields).
    Good command of SQL.
    Strong programming and scripting skills in Python (packages: pandas, NumPy, matplotlib, scikit-learn, TensorFlow, PySpark, etc.).
    Minimum 3 years of experience in related fields.
    Hands-on project experience in some of the following areas:
    Predictive analytics: cross-sell/up-sell modelling, churn prediction, demand forecasting, time series analysis.
    Customer analytics: segmentation, recommendation systems.
    AI and machine learning applications: image processing, natural language processing (NLP).
    Excellent command of English.
    Ability to manage a variety of cross-organizational projects (scope, stakeholders, desired outcomes), working closely with a broad range of internal and external teams.
    Effective communication skills.
    Analytical perspective.

Responsibilities

    Hands on develop the MLOps Infrastructure, Churn Prediction, LTV Prediction, and User Segmentation projects.
    Previous experience in supervised/unsupervised learning for solving various business questions and problems. (e.g., Gradient Boosting, Random Forest, Logistic Regression, K-means Clustering)
    Excellent team member with an ability to clearly communicate at all levels of an organization in a collaborative environment.
    Open-minded for new technologies, always researches and implements newly developed machine learning algorithms.


Requirements

    Bachelor’s with analytical background, preferably in a quantitative discipline Mathematics, Engineering, Economics, MIS, Statistics etc.
    2+ years of work experience in the Data Science field.
    Previous experience in gaming or e-commerce is preferred for understanding user behavior.
    Strong knowledge of Python, SQL or relevant statistical tools.
    Excellent analytical skills and attention to details.
    Strong verbal and written communication skills in English.

Who You Are?


·BS degree in Computer Engineering or a related fields

·Min 3+ years of experience with data related roles!

·Min 3+ years of professional experience with SQL querying

·Experience in scripting using Python

·Knowledge of Big Data ETL Tools such as Oozie, Airflow etc.

·Knowledge of Hadoop components such as HDFS, Yarn, MapReduce, Spark, Flink, Hive, Hue, Sqoop, Nifi, Superset etc.

·Experience in Cloudera is a huge plus!

·Experince with Spark Streaming projects!

·Strong Unix / Linux background

·Experience with agile development methodologies such as Scrum.

·B2+ Level Proficiency in English



What You Will Do?


·Develop and design data collection pipeline

·Develop and administer data standards, policies and procedures

·Perform data analysis, development activities and implementation

·Analysis and Integration of new data resources according to data mappings

·Optimize data progressing flows

·Migrate legacy technologies to current technologies

Responsibilities

- Develop and implement AI-powered agents

- Work with Natural Language Processing (NLP) and LLMs (Large Language Models) to enhance conversational AI.

- Integrate AI models into WhatsApp, web applications, and CRM platforms.

- Design and optimize AI responses to handle pre-op and post-op patient queries.

- Ensure data privacy, security, and compliance (HIPAA, GDPR).

- Collaborate with backend and frontend developers to integrate AI functionalities.

- Monitor AI performance and fine-tune models to reduce errors and hallucinations.

- Research and implement cutting-edge AI techniques to enhance user experience.

Requirements

- Strong programming skills in Python, TensorFlow, PyTorch, LangChain, or similar AI frameworks.

- Experience with NLP, chatbot development, or AI-powered automation.

- Understanding of API integrations and cloud-based AI solutions.

- Familiarity with healthcare systems, CRM platforms, or medical AI applications is a plus.

- Ability to troubleshoot and optimize AI models for accuracy and efficiency.

- Knowledge of ethical AI practices, bias reduction, and regulatory compliance.

- Passion for AI-driven healthcare innovations

- Strong problem-solving skills and team collaboration mindset.

Ne Bekliyoruz?

    Bilgisayar Bilimleri, Yapay Zeka, Makine Öğrenimi veya ilgili bir alanda Yüksek Lisans derecesi.
    Doktora derecesi güçlü bir tercih sebebidir.
    Büyük Dil Modellerinin (LLM'ler) eğitimi ve özellikle ince ayarı (fine-tuning) konusunda kanıtlanmış, derinlemesine endüstri veya araştırma tecrübesi,
    RLHF, DPO ve/veya benzeri gelişmiş LLM hizalama ve ince ayar teknikleri hakkında güçlü teorik bilgi ve pratik uygulama deneyimi,
    Python programlama diline ve PyTorch, TensorFlow, JAX gibi derin öğrenme kütüphanelerine (özellikle PyTorch) ileri düzeyde hakimiyet,
    Hugging Face Transformers, PEFT (Parameter-Efficient Fine-Tuning) gibi LLM ekosistemi araçları ve kütüphaneleri konusunda deneyim,
    Güçlü makine öğrenimi temelleri, model değerlendirme metrikleri ve istatistiksel analiz bilgisi,
    Karmaşık teknik problemleri analiz etme, yenilikçi çözümler geliştirme ve bunları uygulama becerisi,
    İyi derecede İngilizce (teknik literatürü takip edebilmek ve potansiyel olarak uluslararası ekiplerle çalışabilmek için),
    Takım çalışmasına yatkınlık ve güçlü iletişim becerileri,
    Tercihen;
    Açık kaynak LLM projelerine (örn. model geliştirme, kütüphane katkısı) katkıda bulunmuş olmak,
    MLOps prensipleri ve araçları (Docker, Kubernetes, MLflow, Weights & Biases vb.) hakkında bilgi sahibi olmak,
    On premise / Bulut platformları üzerinde model eğitimi ve dağıtımı deneyimi,
    Yapay zeka / makine öğrenimi alanında (tercihen LLM üzerine) konferans veya dergi yayını yapmış,
    Güçlü problem çözme, analitik düşünme ve teknik karar alma yeteneği olan,
    İletişim yeteneği güçlü ve ikna kabiliyeti yüksek; farklı paydaşlarla etkili bir şekilde etkileşim kurabilen,


Turkcell’de Artifical Intelligence & Machine Learning Engineer Rolü Ne Yapar?

    Ürün hedeflerimiz ve veri setlerimiz için en uygun açık kaynaklı LLM'leri araştırır değerlendirir ve seçer,
    Toplanan veriyi kullanarak LLM'ler üzerinde etkili ince ayar (fine-tuning) stratejileri tasarlar ve uygular,
    İnsan Geri Bildiriminden Pekiştirmeli Öğrenme (RLHF), Doğrudan Tercih Optimizasyonu (DPO - Direct Preference Optimization) ve benzeri gelişmiş LLM ince ayar metodolojileri konusunda derinlemesine bilgi sahibidir ve bunları aktif olarak kullanır,
    Gerektiğinde, belirli görevler için LLM'lerin sıfırdan eğitimi süreçlerini yönetir veya bu süreçlere katkıda bulunur,
    Model performansını (doğruluk, hız, maliyet, güvenlik vb.) sürekli olarak izler, değerlendirir ve iyileştirmek çin metrikler ve değerlendirme protokolleri geliştirir,
    Modelleri çıkarım (inference) performansı ve maliyet etkinliği açısından optimize etmek,
    Etkili ve güvenli komut (prompt) tasarımları oluşturur ve komut mühendisliği (prompt engineering) süreçlerine katkıda bulunur,
    MLOps ve Backend ekipleriyle yakın iş birliği içinde çalışarak modellerin ölçeklenebilir ve güvenilir bir şekilde üretim ortamına dağıtımını (deployment) sağlar,
    LLM alanındaki en son akademik araştırmaları, açık kaynak projelerini ve endüstri trendlerini yakından takip eder ve bu bilgileri ekibe ve ürüne entegre eder.

Key Skills & Experience Required

    Proven use of model compression or optimization techniques
    Hands-on deployment, production, and operation of Machine Learning models and pipelines at scale, including both batch and real-time use cases.
    Hands-on experience developing or training transformer-based LLMs from scratch
    Deep familiarity with transformer architecture, training pipelines, and experimentation
    Help drive optimization, testing, and tooling to improve the quality of the ML deliverables.
    Stay up-to-date with the latest advancements in ML, deep learning, and AWS services to drive innovation within the team.
    Work with the analytics team & stakeholders to understand their objectives in support of formulating, optimizing, and productionising ML models
    Contribute to expanding and improving the infrastructure to support all stages of the ML model lifecycle and deployment in a production environment.
    3 years of commercial experience delivering projects end-to-end


    Exposure to Docker and Containerization ecosystem
    Experience in Kubernetes and any ML Pipeline frameworks such as KubeFlow, MLFlow
    Hands-on experience in LLMs and implementation techniques (RAG etc.)
    Experience in deep learning techniques, libraries and frameworks (TensorFlow, PyTorch, etc.)
    Experience in Google Cloud Platform (BigQuery, CloudRun etc) and deploying ML services to cloud
    Competency in MongoDB, Elasticsearch and vector search frameworks
    Familiarity with graph databases


Aranan Nitelikler:


    Üniversitelerin Bilgisayar Mühendisliği, Yazılım Mühendisliği veya ilgili bölümlerinden mezun,
    Veri alanında 3 yıl deneyimli,
    Temel düzeyde Linux işletim sistemi bilgisine sahip(komut satırı kullanımı, temel sistem yönetimi)
    Docker veya benzeri container teknolojilerini temel düzeyde bilen
    SQL ve veri tabanı yönetimi konusunda bilgili,
    Git veya benzeri sürüm kontrol sistemlerine aşina,
    Öğrenmeye açık, analitik düşünebilen ve ekip çalışmasına yatkın,
    Güçlü iletişim becerilerine sahip,
    İleri düzeyde İngilizce bilgisine sahip,


Görev ve Sorumluluklar:


    Veri hatlarının tasarımına, geliştirilmesine ve iyileştirilmesine katkı sağlamak,
    Verilerin doğru bir şekilde toplanmasını, işlenmesini ve depolanmasını sağlamak,
    Docker gibi container teknolojileri ile veri işleme uygulamalarını kurmak, yönetmek ve optimize etmek,
    Veri doğruluğu ve kalitesinin sağlanmasına yardımcı olmak, olası veri hatalarını tespit etmek ve çözümlemek,
    Veri mühendisliği ekibi ile yakın işbirliği içinde çalışarak projelere katkı sağlamak ve görevleri zamanında teslim etmek,
    Büyük veri platformları ve teknolojilerine dair yeni çözümleri öğrenmek ve bu çözümleri projelerde uygulamak.


Required Qualifications:

    Bachelor’s degree in relevant fields
    Minimum 5 years of experience in relevant fields
    Proficiency in at least one programming language such as Java, R, or Python
    Familiarity with ML frameworks and libraries
    Hands-on experience with MLOps practices and tools
    Experience with containerization and orchestration technologies such as Docker and Kubernetes
    Cloud experience, preferably with AWS
    Preferably having experience in NLP, LLM technologies, and Generative AI models
    Background in data mining and data analysis
    Practical experience building and deploying predictive models
    Strategic thinker with strong problem-solving skills
    Strong time management and ability to prioritize tasks effectively


You’re a match, if you have:


    BS or MS degree in Computer Science, Engineering, Statistics, or a related field.
    5+ years of hands-on experience as a data engineer, DWH/BI engineer, or a similar role.
    Proficiency in English to feel comfortable working in a multinational environment.
    Advanced proficiency in SQL, with the ability to write, optimize, and troubleshoot complex queries for data extraction, transformation, and reporting.
    Solid understanding of data warehousing concepts and best practices.
    Experience using ETL tools like SSIS, ODI, SAP BODS, etc.
    Experience with BI Platforms like PowerBI, QlikSense, OBIEE, Microstrategy, etc.
    Experience with Azure Cloud services (Azure Data Factory, Azure SQL Database, etc.) is a plus
    Experience with relational database systems such as PostgreSQL, Microsoft SQL Server, Oracle, or similar databases.
    Familiarity with dimension modeling, tabular models, and data cube development in Power BI or other related tools.
    Strong problem-solving skills and the ability to think proactively to optimize data systems and processes.
    Excellent communication skills and the ability to collaborate with cross-functional teams to meet business objectives.


Responsibilities

    Design, develop, and optimize recommendation systems, including collaborative filtering, content-based methods, and deep learning-based approaches.
    Build and apply algorithms for user behavior analysis, segmentation, and personalization.
    Develop RAG-based information retrieval systems.
    Fine-tune and deploy commercial & open-source LLMs.
    Design data acquisition and labeling processes, and develop data quality control algorithms.
    Deliver ML products by designing and implementing all data science steps

Qualifications

    BSc degree in Computer Engineering, Industrial Engineering, Mathematical Engineering, Artificial Intelligence, or related fields.
    At least 2 years of experience in data science and MLOps.
    Strong proficiency in Python programming and data science libraries.
    Familiarity with recommendation systems algorithms and concepts.
    Experience in modeling for NLP tasks.
    Hands-on experience with frameworks for building and integrating LLM-based applications.
    Solid understanding of Retrieval-Augmented Generation (RAG).
    Experience with SQL/NoSQL and database structures.
    Familiarity with CI/CD processes.
    Experience with PyTorch, TensorFlow, XGBoost, CatBoost, LightGBM, Hugging Face, and OpenAI tools.
    Proficiency in written and spoken English.
    Ability and motivation to self-teach, enter new domains, and manage ambiguity.

Preferred / Nice-to-have Qualifications

    A MSc degree in a relevant field.
    Solid academic or industrial experience in recommendation systems, user profiling, and human-computer interaction.
    Experience with Kubeflow technology.
    Familiarity with modern big data solutions and distributed computing platforms.
    Hands-on experience with vector and graph database technologies.
    Experience with cloud-based AI services
    Hands-on experience with LangChain, LLamaIndex, or similar frameworks and libraries.
    Understanding of explainable AI concepts and applications.


What you bring


    5+ years of experience in machine learning, fraud detection, or adversarial AI, preferably in security-focused environments.
    Strong background in anomaly detection, behavioral modeling, and adversarial ML techniques for detecting fraudulent activity and bot behavior.
    Experience developing and optimizing real-time ML pipelines for high-speed fraud detection.
    Hands-on experience deploying and fine-tuning LLMs, with a deep understanding of prompt engineering, fine-tuning, and large-scale inference.
    Deep understanding of supervised, unsupervised, and reinforcement learning techniques for adaptive fraud prevention.
    Familiarity with fraud signals, device intelligence, and behavioral analytics for bot detection and risk assessment.
    Experience with vector-based search, feature engineering, and scalable model inference for real-time fraud prevention.
    Ability to collaborate across Threat Research, Infrastructure, and JavaScript Engineering teams to develop end-to-end ML-powered fraud detection.

Genel Nitelikler


    Üniversitelerin Bilgisayar Mühendisliği, Yazılım Mühendisliği, Matematik veya ilgili bölümlerinden mezun,
    Veri mühendisliği veya ilgili alanlarda en az 5 yıl deneyimli,
    Oracle, PostgreSQL, SQL Server veya diğer ilişkisel veri tabanları ile çalışma deneyimine sahip,
    İleri seviyede İngilizce bilgisine sahip,
    ETL araçlarıyla (tercihen Oracle Data Integrator veya benzeri) çalışmış,
    Veri modelleme konularında ileri düzey bilgiye sahip,
    Python veya Java ile veri işleme alanında deneyime sahip,
    Veri yönetişimi, veri güvenliği ve veri kalitesi süreçleri hakkında bilgiye sahip,
    Agile/Scrum metodolojileriyle çalışma konusunda tecrübeli bir ekip arkadaşı arıyoruz.


İş Tanımı


    Şirketin veri altyapısını geliştirmek, optimize etmek ve yönetmek,
    Farklı kaynak sistemlerden veri entegrasyonu sağlamak ve ETL süreçlerini tasarlamak, geliştirmek ve optimize etmek,
    Veri ambarı modelleri oluşturmak ve veri süreçlerinin sürekliliğini sağlamak,
    Büyük veri sistemleri, veri gölleri ve analitik platformlarla çalışarak veri yönetimini ileriye taşımak,
    Veri kalitesini ve güvenliğini sağlamak için gerekli süreçleri tasarlamak ve uygulamak,
    İş zekası ve raporlama ekipleriyle iş birliği yaparak veri modellerini optimize etmek,
    Veri yönetişimi ve metadata yönetimi süreçlerine katkı sağlamak,
    Qlik Sense veya benzeri veri görselleştirme araçlarıyla veri analizi ve raporlama süreçlerine destek olmak,
    Yapay zeka ve makine öğrenmesi projeleri için gerekli veri hazırlık süreçlerini yürütmek, veri setleri oluşturmak ve bu süreçlerin verimliliğini artırmak,
    Model eğitiminde kullanılacak temiz ve anlamlı veri setlerini sağlamak üzere veri akışlarını (pipeline) tasarlamak ve geliştirmek.


Key Responsibilities:

 

    Develop and implement AI algorithms/models for trading, forecasting, and risk management in oil and gas markets.
    Create predictive models for price movements, supply-demand dynamics, and geopolitical risk assessment.
    Design and maintain hedging strategies using derivatives and financial instruments.
    Develop and maintain data pipelines and ensure data quality


    Analyze large-scale market data from multiple sources (e.g., market feeds, economic reports).
    Collaborate with traders, data engineers, and financial analysts to integrate AI models into trading systems.
    Conduct back testing, scenario analysis, and performance evaluation of models.
    Stay updated on emerging AI technologies, trading models, and market regulations.
    3+ years of experience in software development.


 

Qualifications:

 

    BSc, Master’s or Ph.D. in Computer Science, Data Science, Finance, or a related field.
    Proven experience with AI applications in financial trading, commodities, or energy markets.
    Expertise in machine learning frameworks (TensorFlow, PyTorch) and statistical modeling.
    Strong programming skills in Python, R, or C++.
    Familiarity with financial market structures, derivatives, and quantitative finance.
    Experience with time-series analysis, reinforcement learning, and optimization techniques.
    Ability to translate complex data insights into actionable trading strategies.

What You Need To Be Successful:


    Hands-on applied machine learning experience from 2 to 3 years with proven record of statistics, ML model development, data analysis and visualization know-how and experience
    Proficiency with Python and related ML-Data Analysis libraries used for problems in the scope of time series, forecasting and anomaly detection,etc.
    Project completion with deep learning frameworks (like Tensorflow, Keras) especially for RNN for time-series forecasting
    Excellent skills at distilling complex, ambiguous scenarios into tractable model
    Expertise in visualizing and manipulating big datasets
    Familiarity with SQL and experience working with various database types
    Able to support technical meetings worldwide with a fluent command of English
    Familiarity with version control systems, and source code versioning systems such as git/mercurial, issue and know-how tracking solutions like Jira and Confluence, productivity tools for data science such as Jupyter or Azure notebooks


What Makes You A Great Fit (is a plus):


    BSc in Computer Science, Mathematics or similar field; Master’s degree
    Experience on working with sequential big data like time series forecasting and anomaly detection, root cause analysis or geolocation analytics
    High-performance computing, data modeling and query optimization experience
    SW Development techniques, big data technologies and Linux
    Telecommunication domain know-how and working experience
    Executive-level reporting and presentations, data story-telling skills
    Eligible for working in Turkey



Responsibilities:


• Lead data preparation, feature engineering, and model selection processes,

• Understand business requirements and propose appropriate ML solutions,

• Develop models using supervised, unsupervised, and reinforcement learning techniques,

• Deploy scalable and maintainable ML models into production environments,

• Monitor model performance and retrain, when necessary,

• Collaborate closely with software, product, and data teams,

• Continuously improve technically by following new algorithms and research in the field,


Required Technical Skills:


• Bachelor's (preferably Master's or Ph.D.) degree in Computer Science, Artificial Intelligence, Mathematics, Statistics, or a related field,

• Advanced proficiency in Python,

• At least 4 years of experience in developing machine learning models,

• Hands-on experience with ML libraries such as Scikit-learn, TensorFlow, or PyTorch,

• Experience working with big data; familiarity with Spark, Dask, or similar frameworks,

• Knowledge of REST API integration, model serving, Docker, and preferably Kubernetes,

• Practical knowledge of SQL and NoSQL databases,

• Experience with cloud platforms such as AWS, GCP, or Azure.


Preferred Qualifications:


• Experience in specialized fields such as NLP, image processing, or time series forecasting,

• Familiarity with model monitoring tools like MLflow, Weights & Biases, SageMaker, etc.,

• Experience with MLOps (CI/CD, pipeline management),

• Contributions to open-source projects or a background in academic publishing.
Key Responsibilities:

    Lead and manage the development team, providing technical guidance and mentorship.
    Oversee the design, development, and deployment of AI solutions such as intelligent dashboards, AI Agents, and interactive platforms.
    Ensure project deliverables meet quality, scalability, and performance standards.
    Collaborate closely with cross-functional teams, including business developers.
    Foster innovation and continuous improvement within the technical team.


Required Qualifications & Skills:

    Bachelor's degree in Computer Engineering, AI, Data Science, or a related field.
    At least 5 years of experience in AI and software development.
    Proficiency in Python, machine learning, NLP, and data analytics.
    Strong backend experience with Python frameworks such as Django or FastAPI, and familiarity with LangChain.
    Frontend proficiency using React, React Native, or similar frameworks.
    Experience with AI integration (chatbots, virtual assistants).
    Knowledge of cloud infrastructure (AWS, Azure, Google Cloud).
    Familiarity with frameworks like TensorFlow, PyTorch, Hugging Face, OpenAI tools.
    Solid understanding of database management (SQL/NoSQL).
    Strong leadership and project management skills.
    Excellent communication skills in English.

GENEL NİTELİKLER:


    MSSQL ve ilişkisel veri tabanlarında ileri düzey tecrübe
    Daha önce sıfırdan veri mimarisi kurmuş veya migrate süreçlerinde yer almış olmak
    ETL süreçlerinin tasarımı, kurulumu ve yönetimi konusunda kapsamlı bilgi
    Makine öğrenimi ve yapay zeka projelerine veri hazırlama konusunda deneyim
    Büyük veri teknolojileri (örneğin, Spark, Kafka, Hadoop) hakkında bilgi
    Bulut platformlarında (özellikle Azure) veri süreçleri geliştirme deneyimi
    Python veya benzeri bir programlama dilinde ileri düzey bilgi
    Veri modelleme ve performans optimizasyonu becerileri
    Data lake mimarisi tasarımı ve yönetiminde deneyim
    Veri güvenliği ve gizlilik standartlarına uyum konusunda bilgi sahibi 
    CI/CD süreçlerine hâkimiyet
    Veri görselleştirme araçları (Power BI, Tableau vb.) hakkında bilgi
    Azure Data Engineer veya benzeri bir sertifikaya sahip olmak 


İŞİN TANIMI:


    Mevcut veri tabanlarını ve süreçleri analiz ederek optimize etmek
    Sıfırdan veri mimarisi tasarlamak ve/veya mevcut yapıları taşımak (migration)
    Makine öğrenimi ve yapay zeka projeleri için verilerin hazırlanmasını sağlamak
    ETL süreçlerinin tasarlanması, kurulumu ve yönetimini gerçekleştirmek
    Büyük veri araçları ve modern veri işleme teknolojilerini kullanarak veri pipeline'ları oluşturmak
    Verilerin doğruluğunu ve bütünlüğünü sağlamak için gerekli denetimleri ve süreçleri uygulamak
    Performans odaklı çözümler geliştirmek ve veri güvenliğini sağlamak

Responsibilities






    Monitor databases and apply resolutions to database issues
    Tune performance and optimize queries using TSQL
    Deliver high quality, transactionally consistent and efficient enterprise ETL solutions
    Provide support, and documentation of new and existing ETL processes and solutions
    Create and maintain documentation for database architecture
    Perform in-depth data analyses and assist scientists with the design of complex data models
    Engage with product managers and engineers to improve and automate our ETL processes
    Test and perform database patches and upgrades
    Work alongside multiple disciplines within Prorize, such as data engineering, pricing science, product management, and software development


 

Qualifications



Bachelor’s degree in computer science, data science or related fields. Hands on experience working with development and infrastructure teams in doing database design (tables, stored procedures, views etc.), changes and enhancement to new and existing applications. 2 years minimum of hands-on experience working on data ETL. This is mandatory. Mastery of SQL is absolutely essential; second-rate SQL skills are not tolerated. You must have years of hands on experience using SQL concepts on regular basis. Experience supporting interfaces and back-end integration within applications. Ability to work with large datasets in SQL. Performance tuning experience; strong understanding of developing for performance in SQL. Proven ability to prioritize critical workload. Experience with direct client interaction is a plus. Basic level of C# is desirable but not required. Excellent communications and interpersonal skills. Demonstrated proficiency in client and internal written communications. Passionate and enthusiastic over work; has a can-do attitude. Driven to achieve with minimal supervision in a very dynamic and timeline-sensitive work environment.

What You'll Bring

    Bachelors degree in Computer Science, Computer Engineering, or a related field. A Masters degree is a plus, preferably completed or close to completion.
    3 years of hands-on experience in machine learning and model deployment.
    Strong proficiency with Python and Go languages.
    Experience on NoSQL (e.g., MongoDB, DynamoDB) and SQL databases (e.g., PostgreSQL).
    Experience with machine learning libraries like scikit-learn, xgboost/lightgbm/catboost, PyTorch, and/or TensorFlow.
    Experience in scaling applications with containers and container orchestration frameworks such as Kubernetes.
    Working on message queue and streaming systems like Kafka is big plus
    Working on cloud environments like AWS is big plus
    Good knowledge of Caching(Redis, etc)
    Have a strong DevOps mindset
    Proven proficiency in Continuous Delivery and Continuous Integration best practices
    Developing and maintaining services using frameworks such as FastAPI, Go Fiber.
    Previous experience working with GPS data & development and usage of location based services (OSRM, Valhalla, etc.) is a strong plus.
    Interest in applying research methodologies to practical, business-focused


solutions.

    Excellent communication skills with the ability to collaborate effectively within cross-functional teams.


Your Responsibilities

    Develop, fine-tune, and deploy production level machine learning models and pipelines for diverse use cases (e.g., forecasting, risk scoring, sentiment analysis).
    Apply and optimize machine learning and deep learning models.
    Collaborate with cross-functional teams to build and deploy machine learning pipelines and APIs in an Agile working squad.
    Develop scalable models to support tasks such as forecasting, and risk analysis
    Explore academic research methodologies and adapt them to solve business-oriented challenges.
    Maintain high productivity and inspire others to excel


Qualifications:

    BSc / MSc degree in computer engineering, machine learning, deep learning or equivalent work experience
    Minimum 5 years of experience in a related field
    A strong background in Mathematical Modeling, Operations Research, and Statistical approaches
    Experience with statistical packages such as Python, R, GAMS, and SQL
    Experience with optimization packages is a significant advantage
    Experience in leading teams of 2-3 people is a plus
    Experience with PySpark, Airflow, Tableau & software implementation is a plus
    No military obligation or postponement for at least 2 years for male candidates
    English and Turkish proficiency

Key Responsibilities

    Develop and implement AI automation solutions using LLMs such as OpenAI’s ChatGPT.
    Design and integrate AI-based automation workflows into existing systems.
    Utilize RAG systems to enhance AI-driven solutions with contextual information.
    Build and optimize AI integrations using APIs and other automation tools.
    Stay up-to-date with advancements in AI, machine learning, and automation technologies.
    Collaborate with cross-functional teams to identify and implement AI-driven efficiencies.

Qualifications:

    Proven experience in AI automation and integration.
    Strong knowledge of LLMs such as OpenAI GPT models.
    Experience with AI-powered chatbots and automation platforms.
    Understanding of RAG systems and generative AI methodologies.
    Proficiency in working with APIs and AI service providers.
    Ability to translate business needs into AI-driven solutions.
    Strong problem-solving skills and ability to work in a fast-paced environment.


Preferred Qualifications:

    Experience with cloud-based AI solutions.
    Familiarity with natural language processing (NLP) techniques.
    Prior experience in implementing AI solutions in a production environment.

 Basic Qualifications:

    Bachelor’s degree in a technical field (e.g. Engineering, Computer Science, MIS) from a reputable university and/or relevant tech experience
    Strong knowledge of Python
    Strong knowledge of SQL
    Assertiveness, Fast-Learner, Very organized


 Preferred Qualifications:

    (Nice to have) Knowledge of modern, cloud-based data pipeline best practices
    (Nice to have) Experience with large-scale data warehousing architecture, data lake implementation, and data modeling
    (Nice to have) Experience with orchestration frameworks such as Apache Airflow, Argo Workflow
    (Nice to have) Experience with one or more cloud environments (AWS / Azure / GCP)


Key Responsibilities: 
	•	Develop and implement computer vision and image processing algorithms, including 3D vision, camera calibration, image classification, segmentation, and feature extraction
	•	Conduct research and apply advanced techniques in linear algebra, numerical optimization, probability, and statistics to improve image processing solutions
	•	Work with OpenCV and other relevant libraries to develop and optimize vision-based applications
	•	Design and maintain software architecture and APIs, ensuring seamless integration with existing systems
	•	Collaborate with cross-functional teams to implement and refine vision-based solutions
	•	Optimize performance and scalability of computer vision algorithms for real-world applications.   
Requirements:

	•	Master's or PhD in Computer Science or related fields, specializing in Computer Vision and Image Processing
	•	3-5 years of relevant working experience in computer vision applications
	•	Strong expertise in 3D vision, camera calibration, image classification, segmentation, and feature extraction
	•	Proficiency in linear algebra, numerical optimization, probability, and statistics
	•	Hands-on experience with OpenCV and related tools
	•	Excellent programming skills in C/C++ with some experience in Python
	•	Experience in software architecture and API design, with strong integration skills.



Key Responsibilities

Multi-Agent AI Development:
	•	Design and implement multi-agent AI systems using frameworks like CrewAI, LangGraph, and Langchain
	•	Develop agent-based workflows and orchestration logic leveraging agentic design patterns
Prompt Engineering & Reasoning Strategies:
	•	Apply ReAct prompting and Chain-of-Thought reasoning to enhance AI output quality
	•	Assist in fine-tuning LLMs and optimizing prompt-response workflows for task accuracy
Model Integration & Cloud Deployment:
	•	Build and deploy models using Google Cloud and Vertex AI
	•	Implement CI/CD pipelines to support automated model deployment and evaluation
Performance Evaluation & Optimization:
	•	Evaluate AI model performance for accuracy, efficiency, and scalability
	•	Write and maintain evaluation code to benchmark model behavior in distributed environments
	•	Optimize agent coordination and response logic for real-time use cases
Research & Collaboration:
	•	Stay current with advancements in generative AI, multi-agent coordination, and distributed reasoning
	•	Collaborate with cross-functional teams to integrate AI services into product workflows

Qualifications & Skills
	•	1+ years of experience in AI application development
	•	Proficiency in Python or Java for AI system development
	•	Hands-on expertise with Langchain, LangGraph, CrewAI, and Gemini Agent Builder
	•	Experience with ReAct prompting, Chain-of-Thought reasoning, and model fine-tuning
	•	Familiarity with Vertex AI, Google Cloud services, and CI/CD automation tools
	•	Understanding of reinforcement learning, distributed AI, and multi-agent system design
	•	Strong analytical and troubleshooting skills for debugging complex AI workflows
	•	Collaborative team player with effective communication skills
	•	Self-motivated, fast learner, and comfortable working in a dynamic R&D environment
	•	Very strong English communication skills, both written and verbal (essential for global collaboration)



Key Responsibilities:
	•	Design and implement Generative AI algorithms and models, including GANs and diffusion models.
	•	Collaborate with the product team to integrate research into our core platform.
	•	Develop scalable solutions for fashion model generation and virtual try-on experiences.
	•	Conduct research to improve the accuracy and realism of our AR and AI-driven solutions.
	•	Stay up to date with the latest advancements in AI and computer vision to apply innovative solutions to our projects.

You probably are:
	•	A deep learning researcher with a focus on computer vision, having 2+ years of experience and an exceptional eye for detail.
	•	Experienced with generative technologies such as GANs and diffusion models, and enjoy reading the latest papers in these fields.
	•	Product-oriented and passionate about delivering solutions that are used by real people. You thrive in building impactful platforms that users love and iterating based on feedback.
	•	Highly skilled in bringing your research into production, with a strong portfolio of published work and solutions implemented at scale.

You are also:
	•	A friendly, communicative team player who enjoys working in a fast-paced, collaborative environment.
	•	A problem solver who can make quick decisions and evaluate multiple approaches efficiently.
	•	A self-motivated, fast learner who stays ahead of trends and is always eager to adopt new tools and technologies.

Requirements:
	•	Extensive experience in generative AI, particularly with GANs and diffusion models.
	•	An advanced research experience.
	•	Excellent Python programming skills, with a focus on AI and machine learning libraries such as TensorFlow, PyTorch, etc.
	•	Experience with fashion-related image generation or similar fields is a plus.



GENEL NİTELİKLER

	•	Üniversitelerin 4 yıllık bölümlerinden mezun (Bilgisayar Müh., Yapay Zeka Müh., Yazılım Müh., Matematik Müh.),
	•	Analitik düşünme yeteneğine sahip, analiz etme ve problem çözme konusunda yetenekli, sonuç ve çözüm odaklı, iş takip yeteneğine sahip,
	•	Anlatılan kadarına değil sürecin detaylarına da hakim olmak isteyen, meraklı, öğrenme becerisi yüksek,
	•	Minimum 2 yıl deneyimli,
	•	LLM modelleri ile çalışma, LLM destekli sorgu ayrıştırma (multi-step question breakdown),
	•	tokenizer & model yükleme, özel prompt dizaynı, inference süreç yönetimi konusunda deneyimli,
	•	HuggingFace Transformers, pipeline, torch, AutoTokenizer, AutoModelForCausalL bitsandbytes, quantization (4-bit, 8-bit) kütüphaneleri kullanımı hakkında bilgi sahibi,
	•	Open source LLM’lerle virtual enviroment çalışmaları yapılabilen,
	•	LangChain kullanarak LLM ile uygulama bağlantı sağlayan,
	•	ragatouille ile RAG (Retrieval-Augmented Generation) mimarisi, belge dizinleme, index kontrol ve yeniden oluşturma konularında deneyimli,
	•	Fine Tuning, Zero-Few Shot learning konularında deneyimli,
	•	TextLoader ve PyPDFLoader Veri yükleyici kütüphane kullanımını bilen,
	•	CUDA/GPU kullanımı ve GPU ile inference yapabilen,
	•	Özel token yönetimi ve model embedding güncelleme konusunda deneyimli,
	•	OCR ile belge okuma (EasyOCR, PaddleOCR, Qwen) tecrübesi olan,
	•	Uygulama geliştirme ve API tabanlı veri sorgulama & cevaplama sistemleri geliştirme konusunda bilgi sahibi,
	•	Guardrail (NeMo-Guardrails) kullanarak LLM güvenlik sınırlarının yönetilmesi,
	•	Python bilen,
	•	Tercihen .NET Framework /.NET Core platformunda yazılım geliştirme tecrübesine sahip olan,
	•	Literatürü ve dünyadaki iyi uygulamaları takip edebilecek ve ilgili görüşmeleri yapabilecek düzeyde İngilizce bilgisine sahip.


Here’s what you will be doing:

	•	Collaborate with cross-functional teams to identify data-driven opportunities and provide actionable recommendations to drive growth, enhance products, and optimize operations.
	•	Apply statistical techniques and machine learning methods to extract valuable insights from complex datasets.
	•	Develop and implement data models, algorithms, and predictive analytics to enhance product performance and user experience.
	•	Design and execute experiments to evaluate and improve the effectiveness of various data-driven strategies and initiatives.
	•	Contribute to the development and maintenance of data science and machine learning pipelines to ensure the efficient processing of data.
	•	Stay updated with the latest advancements in data science, machine learning, artificial intelligence, and data analysis methods, and proactively integrate innovation to improve the products and operations of Jotform.

Education & Work Experience & Technical Requirements:

	•	Bachelor’s or Master’s degree in Computer Engineering, Electrical Engineering, Math, Statistics, or a related quantitative field.
	•	Professional experience as a Data Scientist, ML Engineer, AI Engineer, or related role.
	•	Strong Knowledge of Python and SQL.
	•	Excellent communication and presentation skills in English.
	•	Hands-on experience with data science - machine learning frameworks and libraries such as pandas, NumPy, and scikit-learn, PyTorch, Tensorflow, Huggingface Transformers.
	•	Understanding of relevant statistical measures such as confidence intervals, the significance of error measurements, development, and evaluation data sets.
	•	Ability to extract, interpret, and present insights from unstructured and structured data.
	•	Preferably hands-on experience with data visualization tools and techniques.
	•	Preferably hands-on experience with Restful APIs.
	•	Preferably hands-on experience in working with Generative AI frameworks and LLMs. (Large Language Models)



Your profile:
	•	Bachelor’s degree in Computer Engineering or a related Engineering discipline with strong quantitative skills; Master’s is a plus.
	•	1–3 years of hands-on experience in Data Science, Machine Learning, or AI projects
	•	Strong proficiency in Python and SQL is essential, with hands-on experience in data manipulation (Pandas, NumPy), machine learning (Scikit-learn), and working with large-scale datasets.
	•	Hands-on experience with LLM ecosystems (OpenAI, Hugging Face, LangChain, vector DBs such as Pinecone or Milvus) and prompt engineering / fine-tuning.
	•	Solid understanding of statistical modeling, data mining, and ML lifecycle: from feature engineering to model tuning, evaluation, and deployment
	•	Familiarity with MLOps practices, such as model monitoring, versioning, automated retraining, and deployment pipelines. Experience with MLflow for experiment tracking, model management, and lifecycle automation is a plus
	•	Experience in managing and optimizing Datamart structures, ensuring data integrity, performance, and scalability
	•	Comfortable building and updating dashboards using Power BI (or similar tools); knowledge of visualization libraries such as matplotlib, seaborn, or plotly is a plus
	•	Excellent communication skills, capable of simplifying complex information into actionable and executable points for both C-level executives and business units
	•	Ability to extract valuable insights from data and adeptly craft engaging narratives that truly resonate with business stakeholders through powerful storytelling
	•	Experience with Git
	•	Agile methodology knowledge is a plus


Your role:
	•	Conduct exploratory data analysis (EDA) to gain deep insights into the dataset, enabling effective evaluation and drawing meaningful conclusions.
	•	Collaborate with cross-functional teams (product, growth, engineering, operations) to translate business needs into data solutions, uncover customer issues, and develop measurable impact.
	•	Take end-to-end ownership of the analytics and modeling lifecycle—from problem framing to deployment—ensuring solutions are robust, scalable, and aligned with business goals.
	•	Develop and maintain machine learning models, ensuring they remain accurate and relevant by monitoring performance, detecting drift, and retraining when necessary.
	•	Implement and oversee MLOps processes, including model deployment, versioning, and automation, to ensure models are efficiently integrated into production environments.
	•	Design and deploy LLM-powered solutions such as retrieval-augmented generation pipelines (RAG), document Q&A systems, and customer service chatbots that drive internal efficiency and enhance customer experience.
	•	Proactively explore emerging techniques in ML and Generative AI, especially those applicable to the insurance domain, and champion their adoption where they create value.



	•	Üniversitelerin Bilgisayar Mühendisliği, Yazılım Mühendisliği veya ilgili bölümlerden mezun,
	•	Python ile yazılım geliştirme konusunda en az 2 yıl deneyimli,
	•	Uçtan uca makine öğrenmesi ile yazılım geliştirme ve yaşam döngüsü takibi deneyimi,
	•	Yeniden kullanılabilir ve iyi dokümante edilmiş kodlama becerisine sahip,
	•	TensorFlow veya PyTorch gibi makine öğrenmesi framework'lerinde deneyim sahibi,
	•	REST API tasarımı ve geliştirme tecrübesi olan,
	•	Yüksek yüklü (high load) yazılım ve veri sistemleri geliştirme konusunda deneyim sahibi,
	•	Konuşma Tanıma (STT) ve Metin-Konuşma Dönüştürme (TTS) teknolojileri ile çalışma deneyimi,
	•	Görüntü işleme ve bilgisayarlı görü uygulamaları geliştirme yetkinliği,
	•	Büyük Dil Modelleri (LLM) fine-tuning ve optimizasyon konusunda bilgi,
	•	Git ve versiyon kontrol sistemleri bilgisi,
	•	Etkili iletişim, önceliklendirme ve zaman yönetimi becerilerine hakim,
	•	İyi derecede İngilizce (okuma/yazma) bilgisine sahip.

TERCİH EDİLEN NİTELİKLER

	•	Doğal dil işleme (NLP) veya görüntü işleme projelerinde deneyim,
	•	Retrieval Augmented Generation (RAG) mimarileri tasarlama ve geliştirme deneyimi,
	•	Docker, Kubernetes gibi konteynerizasyon teknolojileri bilgisi,
	•	CI/CD pipeline oluşturma ve yönetme deneyimi,
	•	Bulut platformlarında (AWS, Azure, GCP) yapay zeka servisleri kullanımı,
	•	Vektör veritabanları (Pinecone, Weaviate, Chroma vb.) deneyimi,
	•	Lojistik veya tedarik zinciri alanında deneyim.

İŞ TANIMI
	•	Büyük ölçekli makine öğrenmesi ve veri sorunları üzerinde çalışmak,
	•	Yüksek kodlama standartları ile makine öğrenmesi uygulamaları tasarlamak ve uygulamak,
	•	Veri bilimci ve diğer ekip çalışanlarının işlerini daha iyi yapmalarını sağlayacak araçlar geliştirmek,
	•	WMS entegrasyonlu sesli asistan gibi lojistik operasyonları için yapay zeka çözümleri geliştirmek,
	•	Sesli komut tanıma (STT) ve sesli yanıt (TTS) sistemleri implementasyonu,
	•	Depo görüntü işleme sistemleri için görüntü analizi algoritmaları geliştirmek,
	•	LLM modelleri üzerinde fine-tuning yaparak lojistik alanına özelleştirmek,
	•	Şirket dokümanlarını kullanarak RAG sistemleri geliştirmek ve WMS entegrasyonu sağlamak,
	•	Geliştirilen modellerin performansını takip etmek ve optimizasyon sağlamak,
	•	Yazılım geliştirme süreçlerini yapay zeka ile desteklemek,
	•	Gerçek zamanlı yapay zeka sistemleri için backend geliştirmek.


What does a "Data Scientist Supervisor" do at Anadolu Efes?

	•	Analyzes all complex data and identify requirements for business enhancement in Project, conducts exploratory data analysis to presents hidden patterns within the data and build new features that completely reflects domain’s use case problem
	•	Develop and implement machine learning models to solve complex business problems.
	•	Exposure to cloud-based data platforms such as Azure
	•	Work with large datasets, perform data preprocessing, and create scalable data pipelines.
	•	Write efficient SQL queries for data extraction, transformation, and analysis.
	•	Develop and improve forecasting models, especially in demand planning scenarios.
	•	Experiment with deep learning techniques and LLMs (Large Language Models) for business applications.
	•	Collaborate with cross-functional teams
	•	Communicate insights and recommendations to stakeholders through reports and dashboards.
	•	Deploys and monitors machine learning models proactively to prevent any deterioration and takes necessary actions to reproduce model
	•	Develops custom algorithms to tackle business problems that cannot be solved through traditional approaches
	•	Stakeholder management

What are the qualifications we look for in a "Data Scientist Supervisor" at Anadolu Efes?

	•	A bachelor's or master's degree in computer science, data science, operations research, statistics, applied mathematics, or a related quantitative field is required,
	•	2-5 years of experience in data science, machine learning, or AI development.
	•	Proficiency in Python and PySpark
	•	Strong skills in SQL for querying and working with large databases.
	•	Experience with model development, feature engineering, model evaluation techniques and MLOPS,
	•	Ability to translate business problems into data-driven solutions.
	•	Strong analytical thinking and problem-solving skills.
	•	Experience with big data technologies (Spark, Hive).

Nice-to-Have Qualifications:

	•	Experience in demand planning and sales forecasting models is a big plus,
	•	Experience in recommendation models is plus,
	•	Knowledge in deep learning is plus
	•	Familiarity with Large Language Models (LLM) and their applications is plus

bout the Position

	•	M.Sc. degree in machine learning or computer science; OR equivalent work experience delivering state-of-the-art AI/ML solutions
	•	1-2 year(s) of industry experience in developing and delivering robust software solutions, including demonstrated advanced programming expertise in Python.
	•	Experience in at least one major deep learning framework (PyTorch, Tensorflow, XGBoost, Keras, Sklearn)
	•	Knowledge of data wrangling using pandas, MySQL and/or AWS S3
	•	Practices software engineering best practices including version control (eg. Github), object-oriented programming 
Nice to Have

	•	Background or interest in wireless communication
	•	Knowledge of Large Language Models (LLMs) or time series analysis
	•	Having publications is a plus
	•	Experience in Scala or Pyspark
	•	Experience with AWS Sagemaker
	•	Experience in deploying ML models
	•	Contributions to relevant open-source projects. 
Responsibilities

	•	End-to-end implementation of ML projects (including data collection and processing, model development)
	•	Deploying and maintaining production-ready ML models
	•	Collaborating with Engineering, Product and DevOps to deliver ML features via specs
	•	Preparing technical presentations and reports 


Görev ve Sorumluluklar

	•	İş birimleriyle yakın çalışarak dijitalleşme ve AI entegrasyonu odaklı projelerde teknik liderlik yapmak
	•	Uçtan uca yapay zekâ çözümleri geliştirmek: veri toplama, ön işleme, model geliştirme, modelleme sonrası entegrasyon
	•	Üretken yapay zeka araçlarının (ChatGPT, Claude, Copilot, vb.) iş süreçlerine adaptasyonunu sağlamak
	•	Python, JavaScript gibi dillerle AI destekli mikro servisler ve otomasyon çözümleri geliştirmek
	•	OpenAI, Hugging Face gibi platformlardan faydalanarak özel çözümler üretmek
	•	AI çözümlerini mevcut uygulamalara entegre etmek; API’lerle sistem bağlantılarını kurmak
	•	Yazılım geliştirme ekipleriyle koordineli çalışarak modüler, sürdürülebilir AI çözümleri üretmek
	•	Mevcut süreçleri analiz ederek yapay zekâ ile otomasyon ve optimizasyon projeleri yürütmek
	•	Şirket genelinde yapay zeka farkındalığı oluşturmak, iç eğitimler düzenlemek
	•	AI kullanımını ölçen raporlama sistemleri ve KPI altyapıları kurmak
	•	Yeni teknolojileri ve trendleri yakından takip ederek uygulanabilir fikirler geliştirmek

Aranan Nitelikler

	•	Bilgisayar Mühendisliği, Yapay Zeka, Veri Bilimi veya benzeri alanlarda lisans veya yüksek lisans
	•	En az 5 yıl yazılım geliştirme deneyimi (tercihen Python veya JavaScript)
	•	En az 2 yıl yapay zeka / makine öğrenmesi projelerinde aktif rol almış olmak
	•	AI/ML framework’lerinde deneyim sahibi olmak (TensorFlow, PyTorch, Scikit-learn vb.)
	•	RESTful API tasarımı, veri tabanı yönetimi (SQL/NoSQL), yazılım mimarisi konularında deneyim
	•	ChatGPT, GPT-4, Claude, LLM’ler ve üretken yapay zeka modellerine aşinalık
	•	Prompt engineering konularında bilgi sahibi olmak
	•	Tercihen LangChain, LlamaIndex, RAG gibi frameworklerle çalışmış olmak
	•	Dijital dönüşüm ve AI entegrasyon projelerinde görev almış olmak tercih sebebidir
	•	Güçlü analitik düşünme, problem çözme yeteneği ve etkili iletişim becerisi
	•	Takım çalışmasına yatkın, sonuç odaklı, yeniliklere açık


Responsibilities

	•	Develop, train, and optimize large language models [LLMs] using state-of-the-art architectures such as Mixtral, Qwen, etc.
	•	Apply advanced NLP techniques, including Retrieval-Augmented Generation [RAG], zero-shot/few-shot learning, and in-context learning.
	•	Implement efficient fine-tuning methods such as LoRA and QLoRA.
	•	Research and apply inference-time optimization techniques such as quantization, ONNX Runtime, and TensorRT.
	•	Design and deliver solutions for complex NLP tasks, including multi-step reasoning, question answering, and code generation.
	•	Define evaluation metrics, perform thorough error analysis, and ensure the reliability and ethical use of models.
	•	Take technical leadership in the formation of a new AI team and contribute to recruitment processes.
	•	Actively participate in and technically coordinate R&D projects across our İzmir and London offices.

Required Qualifications

	•	Minimum 5 years of experience in AI, machine learning, and NLP.
	•	Advanced proficiency in transformer-based architectures [e.g., GPT, BERT, LLaMA].
	•	Expert-level skills in training and deploying models using PyTorch and/or TensorFlow.
	•	Experience in distributed training and working with multi-GPU or multi-node environments.
	•	Solid knowledge of data curation, large-scale dataset preparation, and ethical data handling.
	•	Proficiency in prompt engineering and modern LLM usage paradigms.
	•	Strong communication, project management, and team leadership skills.
	•	Full professional fluency in English [spoken and written].

Preferred Qualifications

	•	Experience in GoLang development.
	•	Knowledge of RLHF [Reinforcement Learning from Human Feedback] and alignment techniques.
	•	Practical experience with MLOps and deploying LLMs into production environments.
	•	Familiarity with MLflow, Kubeflow, or cloud-based ML platforms [AWS SageMaker, Azure ML, GCP AI].
	•	Awareness of ethical AI principles, bias detection, and responsible AI development.
	•	Contributions to open-source AI projects or active involvement in research communities.

Candidate Profile:

	•	3+ years of software development experience with Python knowledge
	•	Experience in fine-tuning large language models (LLM), optimizing performance, deploying scalable solutions, and integrating advanced NLP and NLU techniques into production systems
	•	Bachelor’s degree in computer science, data science, statistics, applied mathematics, or a related discipline
	•	Experience in Python API development with known frameworks
	•	Advanced experience in pattern recognition and predictive modeling.
	•	Experience in prompt engineering
	•	Proficiency in SQL and Python, as well as a strong understanding of the core language and major frameworks
	•	Experience with cloud platforms such as AWS or Azure
	•	Solid knowledge of Git for version control and Linux for development environments
	•	Proven results influencing stakeholders and demonstrating results
	•	Ability to translate complex problems and ideas into easily understood descriptions
	•	Ability to work independently, self-starter, can-do attitude, multitask, and prioritize
	•	Advanced speaking proficiency in English to be part of international calls when needed
	•	Work location is Kozyatagi, Istanbul; at least 2/3 days a week at the office
	•	No military obligations



Some details on the tasks - if you are still with us:

	•	Improve and maintain the existing Spiky web platform APIs.
	•	Create robust integrations with various productivity tools (e.g., Notion, Slack) and CRM platforms (e.g., Salesforce, HubSpot).

Some Technical Skills 🍕

	•	Strong proficiency in Python or an object oriented language
	•	In-depth understanding of data structures, algorithms, Clean Code, and SOLID principles
	•	Proficiency in designing and developing RESTful APIs and backend services called by different clients.
	•	Experience with Testing methods, including unit and integration tests.
	•	Experience in working with databases (SQL, NoSQL)
	•	Understanding of how to use APIs/SDKs for developing integrations.

My personal favorite - Cloud Skills ☁️

	•	Understanding of AWS API Gateway.
	•	Familiarity with any infrastructure-as-code (IaC) framework
	•	Experience with AWS security practices, including IAM roles and security groups.
	•	Experience with databases (both SQL and NoSQL), as well as knowledge of data storage options in AWS (such as Amazon RDS, DynamoDB).


Basic Qualifications:
	•	Bachelor’s degree in a technical field (e.g. Engineering, Computer Science, MIS) from a reputable university and/or relevant tech experience
	•	Strong knowledge of Python
	•	Strong knowledge of SQL
	•	Assertiveness, Fast-Learner, Very organized

Preferred Qualifications:
	•	(Nice to have) Knowledge of modern, cloud-based data pipeline best practices
	•	(Nice to have) Experience with large-scale data warehousing architecture, data lake implementation, and data modeling
	•	(Nice to have) Experience with orchestration frameworks such as Apache Airflow, Argo Workflow
	•	(Nice to have) Experience with one or more cloud environments (AWS / Azure / GCP)

Responsibilities:
	•	Working closely with our clients and consultants in analytics projects
	•	Building and designing scalable data pipelines using various technologies and environments (Cloud / On-Prem)
	•	Developing data set processes for data modeling, mining, and production
	•	Responsible for data integration, transformation, quality, and preparation of data-centric solutions like data warehouse, data lake, and data analytics projects
	•	Research opportunities and new technologies to improve existing systems


Yetkinlikler:

İletişim ve Koordinasyon
	•	Teknik konuları teknik olmayan kişilere anlaşılır şekilde aktarabilme
	•	Farklı departmanlarla etkin iletişim kurabilme
	•	Sunum ve ikna kabiliyeti
Proje Yönetimi
	•	Çoklu proje yönetimi becerisi
	•	Teknoloji satın alma ve değerlendirme süreçlerini yönetebilme
	•	POC çalışmaları tasarlayabilme
	•	Stratejik düşünebilme ve yol haritası oluşturabilme
Sürekli Öğrenme
	•	Yapay zeka teknolojilerindeki güncel gelişmeleri yakından takip etme
	•	Hızla değişen teknolojilere adaptasyon yeteneği
	•	Araştırmacı ve meraklı bir çalışma yaklaşımı
Kişisel Özellikler
	•	Analitik düşünme becerisi
	•	Detaylara özen gösteren bir çalışma yaklaşımı
	•	Takım çalışmasına yatkınlık
	•	Proaktif ve inisiyatif alabilen bir profil
	•	Teknolojik yeniliklere açık ve heyecanlı
Eğitim ve Sertifikasyon
	•	Bilgisayar Mühendisliği, Yazılım Mühendisliği veya ilgili alanlarda lisans/yüksek lisans
	•	AI/ML sertifikaları (Google Cloud Professional ML Engineer, AWS Machine Learning Specialty vb.)
	•	Uluslararası geçerliliği olan AI ve veri bilimi sertifikaları
Teknik Yetkinlikler
	•	Python, TensorFlow, PyTorch programlama dillerinde uzman
	•	LLM (Large Language Models) mimarisi ve çalışma prensiplerini derinlemesine anlama
	•	Bulut platformları (AWS, Azure, GCP) üzerinde AI/ML çözümleri kurgulayabilme
	•	Doğal dil işleme (NLP) ve generative AI modellerini anlama
	•	API entegrasyonları ve mikroservis mimarileri konusunda bilgi
Deneyim
	•	Tercihen 3-5 yıl AI/ML proje deneyimi
	•	En az bir generative AI projesinde aktif rol almış olmak
	•	Endüstriyel AI çözümleri geliştirme tecrübesi

	•	BSc degree in Computer/Industrial Engineering or similar academic disciplines
	•	Experience in relational databases and proficiency in SQL
	•	Competency and considerable experience in Python
	•	Experience in creating and deploying machine learning systems and pipelines would be a great asset
	•	Fundamentals in predictive modeling, statistics and ML techniques, libraries and frameworks (pandas, NumPy, scikit-learn, SciPy, XGBoost, HuggingFace etc.)
	•	Basic project management skills to plan, execute, and deliver data science projects
	•	Fluency in English (written & spoken)

🎯Your Journey Begins: Embrace the Exciting Adventure Ahead!

	•	Exposure to Docker and Containerization ecosystem
	•	Experience in Kubernetes and any ML Pipeline frameworks such as KubeFlow, MLFlow
	•	Hands-on experience in LLMs and implementation techniques (RAG etc.)
	•	Experience in deep learning techniques, libraries and frameworks (TensorFlow, PyTorch, etc.)
	•	Experience in Google Cloud Platform (BigQuery, CloudRun etc) and deploying ML services to cloud
	•	Competency in MongoDB, Elasticsearch and vector search frameworks
	•	Familiarity with graph databases
Veri Bilimi Uzmanı’nın sorumlulukları neler?

	•	İş birimleriyle yakın çalışarak analitik ihtiyaçlarını anlamak, buna uygun analitik çözümler sunmak,
	•	Kompleks veri setlerini stratejik öngörüye dönüştürmek,
	•	Modelleme öncesi süreçlerinin tüm aşamalarında (veri toplama, temizleme ve analiz etme) yer almak ve süreçleri iyileştirmek.
	•	Analitik modeller tasarlamak ve geliştirmek, (denetimli/denetimsiz öğrenme, optimizasyon, fiyatlama, vb.)
	•	Geliştirilen analitik çözümlerin iş kullanıcılarına, yöneticilere ve üst yönetime aktarımını yapmak ve model yaşam döngüsü içinde yer alan paydaşlarla işbirliği içinde çalışmak,
	•	Geliştirilen modellerin canlıya alınma sürecinde aktif rol almak ve bu modellerin performans takibi/bakımını yapmak, yapılmasını sağlayacak otomasyon süreçlerini oluşturmak ve modelleri düzenli periyotlarla güncellemek,
	•	Veri bilimi alanındaki yenilikleri/ trendleri araştırmak, projelerde uygulamak ve ekibe aktararak bilgi paylaşımını desteklemek,
	•	Fiyat stratejilerine yönelik simülasyon ve kontrollü deneyler (A/B testleri) tasarlama, analiz etmek,
	•	Doğrusal ve/veya tamsayılı programlama araçlarıyla fiyat-odaklı optimizasyon modelleri kurmak (PuLP, Pyomo, SciPy.optimize),
	•	Fiyat temelli churn modelleri (ör. survival analysis) geliştirerek müşteri kaybı riskini tahmin etmek,

Bu rol için aradığımız nitelikler neler?

	•	Üniversitelerin İstatistik, Bilgisayar mühendisliği, Matematik mühendisliği, Endüstri mühendisliği ve benzeri bölümlerden mezun ya da bu alanlarda yüksek lisansı bulunan,
	•	Analitik alanda en az 3 yıllık deneyimi olan,
	•	İleri düzeyde SQL bilgisine sahip, ilişkisel veri tabanları kavramları hakkında bilgi sahibi olan,
	•	Python, Spark, R gibi veri analizi ve istatistiksel programlama dillerini kullanabilen,
	•	Makine öğrenimi, fiyatlama, öneri sistemleri ve optimizasyon süreçlerinde model geliştirme deneyimine sahip,
	•	Tercihen banka ya da perakende sektöründe fiyatlama projelerinde görev almış olan ve gelir yönetimi (revenue management) veya fiyat optimizasyonu yaklaşımlarını gerçek projelerde uygulamış olmak,
	•	Analitik düşünme ve problem çözme yetkinliğine sahip,
	•	Veriyi analiz etme ve etkin şekilde yorumlama, veri görselleştirme konularında deneyimi olan,
	•	Sunum, ikna ve yazılı-sözlü iletişim becerileri gelişmiş,
	•	Takım çalışmasına yatkın,
	•	İleri seviyede İngilizce bilen.


Responsibilities;

	•	Strong knowledge of SQL and Python; excited to learn new languages when needed,
	•	Experience in working with a cloud data warehouse (Snowflake, Redshift, BigQuery) is a plus,
	•	Excellent attention to detail, natural curiosity and ability for creative problem-solving,
	•	Strong written and oral communication skills,
	•	Ability to work independently with minimal supervision and prioritize multiple tasks in a fast-paced environment,
	•	Excellent analytical thinking / problem solving skills and attention to detail,
	•	Ability to deal with ambiguity in defining activities and direction with good planning skills.

Qualifications;

	•	University degree from a reputable university in a STEM (Statistics, Mathematics, Engineering) field or related departments,
	•	At least 1 - 2 years' of experience in quantitative analytics or data modeling,
	•	Experience with PySpark, Airflow, Tableau,
	•	Experience with software implementation,
	•	Strong background in Mathematical Modeling, Operations Research, Statistical approaches,
	•	Experience with statistical packages such as Python, R, GAMS and SQL is a big plus.




Skills & Requirements

	•	Minimum BS Degree in Software/Computer/Electrical&Electronics Engineering.
	•	Hands on experience on machine learning problems.
	•	Solid experience in implementing software solutions in enterprise Linux or Unix environments.
	•	Solid programming background in Python.
	•	Experience on NLP tools, seq-to-seq models, transformers, LLMs is a plus.
	•	Solid experience on open source LLM models, fine-tuning, RAG, Knowledge Graphs is a big plus.
	•	Candidates are expected to keep themselves up-to-date with the latest ML/DL research and developments in the world.
	•	Knowledge of Agile software development methodologies is a plus.


Benefits

	•	You will directly work with highly experienced researchers and academicians with extensive experience on machine learning and deep learning. We encourage you to publish papers and write patents.
	•	We highly encourage applicants to pursue MS and PhD degrees, and help them to accomplish these goals.
	•	We provide seminars and lectures on data analysis, machine learning and deep learning topics. You will enrich yourself in the most state-of-the-art tools and technologies.
	•	We offer highly competitive salary packages, which are highly flexible based on merit and performance.
	•	Social/ Side Benefits: Private Health İnsurance, Restaurant Ticket (MultiNet Card), Birthday off, Annual Elective Benefits.

What You'll Do:
	•	Develop and implement generative AI solutions, including chatbots, code generation, and creative content generation for diverse applications.
	•	Build and optimize AI-driven applications leveraging state-of-the-art models for tasks such as text-to-text, text-to-image, image-to-text, and text-to-video.
	•	Fine-tune and deploy large-scale language models (LLMs), ensuring efficient performance and scalability.
	•	Collaborate with cross-functional teams to create AI solutions tailored to the tourism industry and other sectors.
	•	Stay updated with the latest trends and research in generative AI and integrate them into production systems.
	•	Work on multimodal systems and explore innovative AI-driven technologies.
	•	Provide technical leadership, promote best practices in AI model development, and ensure high-quality code and seamless integration.
	•	Work on AI code development and related tasks, including model implementation and optimization.

Who You Are:
	•	Bachelor’s degree in Computer Science, Engineering, or a related field.
	•	At least 2+ years of relevant experience in generative AI, machine learning, or deep learning.
	•	Strong knowledge of machine learning and deep learning algorithms (e.g., CNN, LSTM, NLP, and transformers).
	•	Experience with cloud technologies and deployment of AI models.
	•	3+ years of Python programming and data science experience.
	•	Proficiency in working with LLMs and other generative models.
	•	Familiarity with multimodal models and applications, such as text-to-image, text-to-video, and video-to-text.
	•	Vast analytical problem-solving capabilities and experience in model fine-tuning and optimization.
	•	Experience in AI code development, including model implementation and optimization.
	•	Good English communication skills, with the ability to clearly articulate complex technical concepts.



Here’s what you will be doing:

	•	Collaborate with cross-functional teams to identify AI-driven opportunities and provide actionable recommendations to drive growth, enhance products, and optimize operations.
	•	Apply advanced artificial intelligence and machine learning techniques to create high-quality and high-impact products.
	•	Participate in the design, development, testing, deployment, and maintenance of new AI models, products, and data pipelines.
	•	Develop and implement AI products to enhance product performance and user experience.
	•	Design and execute experiments to evaluate and improve the effectiveness of various AI-driven strategies and initiatives.
	•	Contribute to the development and maintenance of Jotform’s AI infrastructure.
	•	Stay updated with the latest advancements in artificial intelligence, machine learning, and statistical modeling techniques, and proactively integrate innovative approaches into Jotform’s AI products and machine learning solutions.

Education & Work Experience & Technical Requirements:

	•	Bachelor’s or Master’s degree in Computer Engineering, Electrical Engineering, Math, Statistics, or a related quantitative field.
	•	Professional experience as an AI Engineer, ML Engineer, Data Scientist, or related role.
	•	Strong Knowledge of Python and SQL.
	•	Excellent communication and presentation skills in English.
	•	Hands-on experience with AI and machine learning frameworks such as Huggingface Transformers, PyTorch, Tensorflow, and scikit-learn.
	•	Solid knowledge of Restful APIs, preferably hands-on experience on FastAPI.
	•	Ability to extract, interpret, and present insights from unstructured and structured data.
	•	Experience in productionizing AI systems at scale.
	•	Experience in working with Large Language Models(LLMs) and Generative AI frameworks.


Sorumluluklar:
	•	Pazarlama süreçlerinde AI destekli otomasyon sistemlerinin geliştirilmesi (performans analizi, segmentasyon, içerik öneri sistemleri vb.)
	•	Makine öğrenmesi modelleri ile yeni pazar analizleri yaparak potansiyel distribütör/ortak şirketleri belirlemek
	•	E-ticaret ve dijital reklam kanallarında AI destekli stratejilerin uygulanması
	•	CRM, sosyal medya ve dijital kampanyalarla entegre çalışan karar destek sistemlerinin oluşturulması
	•	Ürün öneri algoritmalarının geliştirilmesi ve dönüşüm oranlarının artırılmasına katkı sağlamak
	•	AI ile veri odaklı karar süreçlerinin şirket genelinde yaygınlaştırılması

Aranan Nitelikler:

	•	Yapay zeka, makine öğrenmesi, veri bilimi veya ilgili alanlarda lisans veya yüksek lisans mezunu
	•	Python, SQL, TensorFlow, Scikit-learn, vb. araçlarda deneyimli
	•	Dijital pazarlama süreçlerine aşina, CRM ve Google Analytics gibi platformları analiz edebilen
	•	Tercihen sağlık ürünleri, e-ticaret ya da FMCG sektöründe deneyim sahibi
	•	Analitik düşünce yapısına sahip, proje bazlı çalışma sistemlerine uyumlu
	•	Takım çalışmasına yatkın, sonuç odaklı, iletişim becerileri güçlü
	•	İyi derecede İngilizce bilen


Responsibilities:
	•	Design, develop, and maintain geospatial databases and servers.
	•	Enable data integration between geospatial databases and Unity.
	•	Develop REST APIs for data exchange.
	•	Use Geoserver and tilemap server for geospatial data handling.
	•	Ensure GIS data integrity across formats.
	•	Create Windows desktop apps for geospatial data visualization.
	•	Collaborate for seamless geospatial tech integration.
	•	Provide technical support for geospatial applications.

Required Qualifications:
	•	Bachelor’s degree in Computer Science, or a related field.
	•	Minimum of 6 years of working experience
	•	Proficient in developing Windows desktop applications using Python and QT.
	•	Experience with REST API development.
	•	Knowledge of geoserver and tile map server.
	•	Familiarity with various GIS data types and formats.

Nice to Have:
	•	Experience in developing and maintaining databases and local servers for geospatial data.
	•	Knowledge in GDAL and QGIS for data analysis and manipulation.
	•	Knowledge in C++
	•	Strong problem-solving skills and attention to detail.
	•	Experience applying machine learning techniques to analyze and interpret geospatial data.
	•	Excellent communication and teamwork abilities.

İş Tanımı

	•	Farklı yapı ve sistemlerdeki yapılandırılmış/yapılandırılmamış, toplu/gerçek zamanlı verilerdeki ilişkileri keşfetmek ve anlamlandırmak,
	•	Modelleme çalışmaları için gerekli verilerin hazırlanması, temizlenmesi ve anlamlı değişkenlerin oluşturulmasını sağlamak,
	•	Doğal Dil İşleme (NLP) projelerinde BERT ve diğer Transformer tabanlı modelleri kullanarak metin analizi yapmak,
	•	Büyük Dil Modelleri (LLM) ile yenilikçi çözümler geliştirmek,
	•	Makine öğrenmesi, örüntü tanıma, metin madenciliği ve paralel dağıtılmış hesaplama yöntemlerini kullanarak büyük ve karmaşık veri setlerini iş çözümlerine dönüştürmek,
	•	Analitik hizmetlerde kullanılabilecek en yeni teknolojiler ve araçlar hakkında araştırma yapmak, iş kullanım durumları için prototipler geliştirmek,
	•	Mevcut yapılardaki olası fırsatları araştırmak ve uygulanabilir öneriler sunmak,
	•	Makine öğrenmesi ve analitik modelleme projelerinde, veri fırsat ve kısıtlarını anlamak için iş birimleriyle iş birliği yapmak,
	•	Optimizasyon projeleri tasarlamak ve uygulamak, operasyonel süreçleri iyileştirmek,
	•	Müşterilere geri bildirim sağlamak için sunumlar ve görselleştirmeler üretmek veya bunların oluşturulmasına destek vermek,
	•	Analitik projeler kapsamında sektördeki literatürü ve teknolojik gelişmeleri yakından takip ederek iş ile ilgili araştırma ve yazışmalar yapmak.


Nitelikler

	•	Üniversitelerin Mühendislik Fakültelerine bağlı Bilgisayar, Elektrik-Elektronik, Matematik, Endüstri Mühendisliği bölümleri ile Matematik, Fizik ve İstatistik bölümlerinden mezun,
	•	Veri bilimi alanında minimum 3+ yıl tecrübeli,
	•	Etiketli öğrenme, etiketsiz öğrenme ve derin öğrenme yöntemlerini kullanarak proje geliştirmiş,
	•	İstatistik ve büyük veri analizleri, tahminleme, kümeleme ve skorlama modelleri hakkında bilgi ve deneyim sahibi,
	•	BERT ve büyük dil modelleri (LLM) ile gerçek veri üzerinde proje geliştirmiş, embedding ve model optimizasyonu konularında deneyimli,
	•	Features engineering süreçlerine hakim ve değişken türetme deneyimi olan,
	•	Python, Tensorflow, Pytorch gibi veri bilimi alanında kullanılan programlama dillerinde ileri seviyede bilgi ve deneyim sahibi,
	•	İyi seviyede SQL bilgisine sahip,
	•	Tercihen optimizasyon algoritmaları ve yöntemleri hakkında bilgi sahibi,
	•	Tercihen büyük veri altyapı sistemlerinde (Hadoop, Spark, Hive, MapReduce gibi) bilgi sahibi.


Responsibilities
	•	Analyzing large and complex datasets related to player behavior, game performance, and in-game economies to identify trends, patterns, and opportunities.
	•	Building predictive models and machine learning algorithms to optimize player engagement, retention, and monetization.
	•	Creating informative and visually appealing reports and dashboards to communicate findings to stakeholders.
	•	Collaborating with product and marketing teams to provide data-driven insights for game design, feature development, and marketing campaigns.
	•	Staying up-to-date with industry trends and research to incorporate innovative data science techniques and best practices into our processes.

Requirements
	•	Bachelor's or Master's degree in Data Science, Computer Science, Statistics, or a related field.
	•	Proficiency in programming languages such as SQL and Python.
	•	Proven experience in data analysis, machine learning, and statistical modeling.
	•	Experience with data visualization tools (e.g., Tableau, Power BI, Looker).
	•	Strong problem-solving skills and a curious mindset.
	•	Being eager to work in a startup environment and passion for games.
What your day will look like

	•	Develop your understanding of the entire Linux stack, from kernel, networking, and storage, to the application layer
	•	Design, build and maintain solutions that will be deployed on public and private clouds and local workstations
	•	Master distributed systems concepts such as observability, identity, tracing
	•	Work with both Kubernetes and machine-oriented open source applications
	•	Collaborate proactively with a distributed team of engineers, designers and product managers
	•	Debug issues and interact in public with upstream and Ubuntu communities
	•	Generate and discuss ideas, and collaborate on finding good solutions 
What we are looking for in you

	•	Professional or academic software delivery using Python
	•	Exceptional academic track record from both high school and university
	•	Undergraduate degree in a technical subject or a compelling narrative about your alternative chosen path
	•	Confidence to respectfully speak up, exchange feedback, and share ideas without hesitation
	•	Track record of going above-and-beyond expectations to achieve outstanding results
	•	Passion for technology evidenced by personal projects and initiatives
	•	The work ethic and confidence to shine alongside motivated colleagues
	•	Professional written and spoken English with excellent presentation skills
	•	Experience with Linux (Debian or Ubuntu preferred)
	•	Excellent interpersonal skills, curiosity, flexibility, and accountability
	•	Appreciative of diversity, polite and effective in a multi-cultural, multi-national organisation
	•	Thoughtfulness and self-motivation
	•	Result-oriented, with a personal drive to meet commitments
	•	Ability to travel twice a year, for company events up to two weeks long


📱 What You'll Do

	•	Understand business objectives and data requirements, and transform them into valuable insights and analytical solutions.
	•	Manage data analysis processes and prepare datasets for analysis.
	•	Process large datasets using big data technologies.
	•	Develop predictive models, classifications, and clustering solutions using machine learning algorithms.
	•	Present and communicate data results effectively with visualizations.

👩‍💻👨‍💻 Who You Are

	•	Bachelor's degree or higher in Computer Science, Computer Engineering, Statistics, Mathematics, or a similar quantitative discipline.
	•	Extensive experience with SQL.
	•	Proficiency in Python and related data analysis, data manipulation, and modeling libraries (Pandas, NumPy, Scikit-learn, etc.).
	•	Strong understanding of the Data Science model development lifecycle (data understanding, data cleaning, feature engineering, model training, evaluation, and monitoring).
	•	Hands-on experience with machine learning models, statistical methods, and optimization algorithms for real-world problems.
	•	Experience with big data technologies is a plus.

✅ Must-Haves
We are looking for a Data Scientist, so you should have 3+ years of experience in a Data Science role.

What You'll Be Building
A custom-built AI-powered voice dialer capable of:
	•	Making 100s of outbound calls per day
	•	Conversing in real time using LLM-powered responses
	•	Leaving dynamic, personalised voicemails
	•	Logging call outcomes into CRM systems (e.g., Clay, HubSpot)
	•	Routing high-quality responses for recruiter follow-up
	•	Integrating with VoIP systems like Twilio or Plivo
🔍 Your Mission
	•	Design and develop a scalable, modular AI Dialer from scratch
	•	Integrate with VoIP/SIP providers for outbound call functionality
	•	Incorporate voice AI (OpenAI, ElevenLabs, or similar) for real-time natural conversation
	•	Train the system on recruitment scripts and objection handling
	•	Build logic for voicemail drop, retries, and smart call routing
	•	Ensure GDPR/PECR compliance for outbound calls in the UK/EU
	•	Create feedback loops to continuously optimize the AI's performance
✅ You’ll Thrive If You Have:
	•	Strong experience in AI/ML, NLP, or voice AI systems
	•	Hands-on experience with VoIP platforms (Twilio, Plivo, Asterisk, etc.)
	•	Proven track record building or deploying AI call bots or voice assistants
	•	Solid programming skills (Python, Node.js, or similar)
	•	Understanding of LLM integration (OpenAI, Claude, etc.) for real-time dialogue
	•	Bonus: Experience with recruitment tech, CRM automation, or outbound sales tools
🔧 Tech Stack We’d Like You to Use (Or Improve)
	•	Twilio / Plivo / SIP-based VoIP infrastructure
	•	OpenAI / ElevenLabs for natural speech & response
	•	Clay / Apollo / Airtable / Zapier for CRM & automation
	•	Python, TypeScript, or your preferred scalable backend stack
	•	Docker / AWS / serverless infrastructure for deployment


Aranan Nitelikler:

✅ İleri seviye İngilizce yazılı ve sözlü iletişim becerisine sahip olma
✅ NLP, Görüntü İşleme, Desen Tanıma, Makine Öğrenmesi ve Derin Öğrenme alanlarında en az 3 yıl deneyim
✅ AI Agents, LLM’ler (özellikle Fine-tuning ve Prompt Engineering), CNN’ler, MLOps, RAG, Vektör Veritabanları, Bilgi Erişimi, Veri Ön İşleme, PyTorch, OpenAI Modelleri, OpenCV, Özellik Çıkartımı, LangChain gibi alanlarda derin bilgi
✅ Yazılım geliştirme süreçlerinde yüksek yetkinlik
✅ Python ve Node.js/NestJS backend teknolojileri ile AI servisleri geliştirme deneyimi
✅ CI/CD süreçlerinde deneyim
✅ Güçlü problem çözme ve analitik düşünme becerileri
✅ Hem bağımsız hem de ekip içinde etkin çalışabilme yeteneği


Requirements


Essential technical requirements:

	•	Basic computer science and programming languages
	•	Understanding of data structures, data modeling, and software architecture,
	•	Having expertise in object-oriented programming,
	•	Ability to write reusable and easily-maintainable code using beautiful and proper design patterns,
	•	Ability to write robust and optimized code in Python
	•	Strong programming skills (Python, SQL, etc.) and experience with deep learning frameworks (e.g. TensorFlow, PyTorch, Keras)
	•	Familiar with development processes (CI/CD, DevOps, MLOps)
	•	Machine Learning
	•	Solid understanding of Neural Networks in theory such as convex optimization, hessian approximations, conjugate gradient, and Gauss-Newton steps,
	•	Familiarity with modern machine learning frameworks
	•	Recommender System, related NLP and Computer Vision fields
	•	Proven experience as a Machine Learning/AI Engineer or similar role building largescale recommender systems to solve real live-stream problems,
	•	Practical experience in deploying and optimizing ML models in production,
	•	Experience in one of the fields: Deep Learning-based recommender models, NLP tasks (vector semantics such as TF-IDF or neural word embeds, entity labeling, text classification, etc.), Computer Vision tasks (such as Optical Character Recognition, Object Classification, Object detection, etc.)
	•	Working efficiency
	•	Fully-easy working capability in version control systems such as Gitlab or Github,
	•	Experience in Docker for building a simulation of the production environment,
	•	Solid understanding of JSON file, and schema
	•	Academic
	•	Ph.D. degree in computer science, data science, or a related field,
	•	Being published in Articles and Proceedings in reputable journals related to recommenders systems such as ACL and SIGIR is a significant plus 
Responsibilities:
	•	Design, build, and optimize production-grade LLMs and multimodal AI solutions (e.g., text, vision, speech)
	•	Lead full-cycle AI development, from data pipelines and model training to deployment and monitoring
	•	Collaborate with product and software teams to integrate generative AI into enterprise solutions
	•	Spearhead proof-of-concept initiatives and publish insights on emerging techniques
	•	Implement robust MLOps practices using Kubernetes, MLflow, and cloud services (AWS, Azure, GCP)
	•	Advocate for ethical AI principles, ensuring fairness, transparency, and security

Requirements:
	•	BSc/MSc/PhD in Computer Science or related field
	•	Proficiency in Python, ML frameworks (PyTorch, TensorFlow), and transformer-based architectures (Hugging Face, spaCy)
	•	Proven experience fine-tuning and deploying generative models (GPT, Llama, diffusion models)
	•	Familiarity with containerization (Docker), orchestration (Airflow/Kubeflow), and cloud platforms
	•	Experience in distributed computing (Spark, Dask) and optimizing models for performance


Nice to have:
	•	Contributions to open-source AI projects or publications in top-tier conferences
	•	Expertise in prompt engineering, LLM evaluation, and performance-cost optimization
	•	Experience with advanced AI domains (graph neural networks, reinforcement learning)
	•	Active engagement in AI communities (Kaggle, GitHub, arXiv)


Key Responsibilities:

	•	Analyze and interpret large-scale datasets to drive model development and optimization.
	•	Collaborate with cross-functional teams to integrate ML solutions into Shopify's core products.
	•	Design, build, and deploy agents and multimodal LLMs that improve merchant and buyer interactions.
	•	Stay current with the latest advancements in machine learning technologies and frameworks.
	•	Document and share technical insights and best practices across teams.  
Qualifications:

	•	Extensive experience in building and deploying machine learning models at scale.
	•	Proficiency in using ML framework (e.g., TensorFlow, PyTorch) and programming languages like Python.
	•	Strong analytical and problem-solving skills in solving real-world product problems.
	•	Excellent communication skills and the ability to work in a fast-paced, collaborative environment.

Qualifications

	•	•Bachelor’s degree in Computer Science, Engineering, Statistics, or a related field.
	•	5+ years of experience in data engineering and data science roles.
	•	Proficiency in programming languages such as Python, Java, or Scala.
	•	Strong experience with data storage solutions (e.g., SQL databases, NoSQL databases, data lakes).
	•	Expertise in designing and implementing ETL processes and data pipelines.
	•	Hands-on experience with cloud platforms (e.g., AWS, Azure, GCP).
	•	Familiarity with data warehousing and data modeling concepts.
	•	Proven experience with machine learning frameworks and libraries (e.g., TensorFlow, PyTorch, scikit-learn).
	•	Strong problem-solving skills and attention to detail.

Preferred Qualifications:

	•	Master’s or PhD in a relevant field.
	•	Experience with big data technologies (e.g., Hadoop, Spark).
	•	Knowledge of containerization and orchestration platforms (e.g., Docker, Kubernetes).
	•	Familiarity with data visualization tools (e.g., Tableau, Power BI).
	•	Prior experience in an academic/research environment
	•	Excellent verbal, written, and interpersonal communication skills
	•	Flexibility in work schedule as needed

Job Description

	•	Design, develop, and maintain scalable and efficient data pipelines and ETL processes.
	•	Collaborate with cross-functional teams to gather and understand data requirements for various projects.
	•	Implement and maintain data storage solutions, ensuring data availability, integrity, and security.
	•	Perform exploratory data analysis to identify trends, patterns, and anomalies.
	•	Develop and deploy machine learning models for predictive and prescriptive analytics.
	•	Optimize and fine-tune data pipelines for performance and cost efficiency.
	•	Stay up-to-date with emerging trends and technologies in data engineering and data science.


	•	Building smart, scalable, LLM-powered experiences that help Eva with spending insights, support and budgeting.
	•	Improving Finn's ability to guide Eva through onboarding and compliance in a friendly and helpful way.
	•	Translating complex technical challenges into seamless, intuitive features that Eva can rely on.
	•	Collaborating with product, design, and engineering teams to bring AI-powered features to life - quickly and at scale. 
	•	This challenge is perfect for you if

	•	You have deep expertise in NLP and LLMs and have used them in real-world applications.
	•	You have proven software engineering skills, particularly in Python and FastAPI.
	•	You're familiar with deploying AI models in the cloud, ideally AWS and tools such as Docker.
	•	You're a creative problem solver who gets excited about building things that make a real difference.
	•	You're fluent in English and can communicate complex ideas with clarity.
	•	You're user obsessed and love to build with empathy and purpose. 

In This Role, You Will Have a Chance To

	•	Work in a fully developing AI-powered application features by analyzing user needs, designing, coding, testing, documenting, and maintaining existing functionalities.
	•	Contribute to the SDLC (Software Development Life Cycle) process with Python and AI technologies.
	•	Support the team on AI/ML-based projects that enhance our travel technology solutions.
	•	Improve your problem-solving skills, learn and grow in the field of Artificial Intelligence.
	•	If you’re interested in Python and Artificial Intelligence, and would like to support our AI-driven projects, this is the perfect opportunity for you!  
About The Ideal Candidate

	•	Currently pursuing a bachelor's degree and will be in their 4th year of study.
	•	Effective written and oral communication skills in English.
	•	Basic knowledge of Python and a strong willingness to improve and grow in AI.
	•	Interest in or familiarity with machine learning frameworks and tools such as , LangChain / LlamaIndex Azure, or Git, Code is a plus.
	•	Familiarity with version control systems, such as Git.
	•	Basic understanding of APIs and data pipelines.
	•	Motivated to pursue a career in AI/ML.
	•	Eager to explore new technologies, learn innovative methods, and ensure creativity.
	•	A team member who thrives in an inclusive, welcoming and multicultural environment. 


We are looking for you, if you:

	•	Have engineering experience or technical background in IT,
	•	Have curious mindset; you are collaborative and passionate about helping others to grow and improve.
	•	Have experience in managing people, and developing engineering talents (1+ years).
	•	Hands-on experience building complex ML and data pipelines (e.g., in Apache Spark).
	•	Hands-on experience with technologies and frameworks used in ML (e.g., Sklearn, MLFlow, etc.)
	•	Experience with deployment and provisioning automation tools and concepts, e.g., Docker, Openshift, CI/CD.
	•	Knowledge of software engineering best practices (versioning, testing, documentation, etc.)
	•	Excellent communication skills (preferred B2+), capable of working collaboratively in a semi-remote, globally distributed team.

You'll get extra points for:

	•	Strong analytical and problem-solving capabilities.
	•	Knowledge of MLOps architecture and practices.
	•	Hands-on experience with Public Cloud services.
	•	Experience with monitoring and observability (in ML and data domain).
	•	Good understanding of different data storages (e.g., RDBMS, non-SQL, and time-series databases).



